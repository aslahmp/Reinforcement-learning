{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "from gymnasium.envs.registration import register"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aslahmp/anaconda3/envs/RL/lib/python3.10/site-packages/gymnasium/envs/registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment CustomFrozenLake-v0 already in registry.\u001b[0m\n",
      "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "env=gym.make('FrozenLake-v1', desc=None, map_name=\"4x4\", is_slippery=True)\n",
    "# Custom Frozen Lake Environment\n",
    "class CustomFrozenLake(gym.envs.toy_text.FrozenLakeEnv):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(CustomFrozenLake, self).__init__(**kwargs)\n",
    "\n",
    "    def step(self, action):\n",
    "        state, reward, done, truncated, info = super(CustomFrozenLake, self).step(action)\n",
    "        self.goal=env.unwrapped.desc.shape[0]*env.unwrapped.desc.shape[1]-1\n",
    "        if state == self.goal:\n",
    "            reward = 5  # Positive reward for reaching the goal\n",
    "        elif done and state != self.goal:\n",
    "            reward = -5  # Negative reward for falling into a hole\n",
    "        else:\n",
    "            reward =-1\n",
    "        return state, reward, done, truncated, info\n",
    "\n",
    "# Register the custom environment\n",
    "register(\n",
    "    id='CustomFrozenLake-v0',\n",
    "    entry_point='__main__:CustomFrozenLake',\n",
    "    kwargs={'is_slippery': True,\n",
    "          }\n",
    ")\n",
    "\n",
    "# Create the custom environment\n",
    "env = gym.make('CustomFrozenLake-v0', render_mode='human')\n",
    "state = env.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode:  0\n",
      "episode:  1\n",
      "episode:  2\n",
      "episode:  3\n",
      "episode:  4\n",
      "episode:  5\n",
      "episode:  6\n",
      "episode:  7\n",
      "episode:  8\n",
      "episode:  9\n",
      "episode:  10\n",
      "episode:  11\n",
      "episode:  12\n",
      "episode:  13\n",
      "episode:  14\n",
      "episode:  15\n",
      "episode:  16\n",
      "episode:  17\n",
      "episode:  18\n",
      "episode:  19\n",
      "episode:  20\n",
      "episode:  21\n",
      "episode:  22\n",
      "episode:  23\n",
      "episode:  24\n",
      "episode:  25\n",
      "episode:  26\n",
      "episode:  27\n",
      "episode:  28\n",
      "episode:  29\n",
      "episode:  30\n",
      "episode:  31\n",
      "episode:  32\n",
      "episode:  33\n",
      "episode:  34\n",
      "episode:  35\n",
      "episode:  36\n",
      "episode:  37\n",
      "episode:  38\n",
      "episode:  39\n",
      "episode:  40\n",
      "episode:  41\n",
      "episode:  42\n",
      "episode:  43\n",
      "episode:  44\n",
      "episode:  45\n",
      "episode:  46\n",
      "episode:  47\n",
      "episode:  48\n",
      "episode:  49\n",
      "episode:  50\n",
      "episode:  51\n",
      "episode:  52\n",
      "episode:  53\n",
      "episode:  54\n",
      "episode:  55\n",
      "episode:  56\n",
      "episode:  57\n",
      "episode:  58\n",
      "episode:  59\n",
      "episode:  60\n",
      "episode:  61\n",
      "episode:  62\n",
      "episode:  63\n",
      "episode:  64\n",
      "episode:  65\n",
      "episode:  66\n",
      "episode:  67\n",
      "episode:  68\n",
      "episode:  69\n",
      "episode:  70\n",
      "episode:  71\n",
      "episode:  72\n",
      "episode:  73\n",
      "episode:  74\n",
      "episode:  75\n",
      "episode:  76\n",
      "episode:  77\n",
      "episode:  78\n",
      "episode:  79\n",
      "episode:  80\n",
      "episode:  81\n",
      "episode:  82\n",
      "episode:  83\n",
      "episode:  84\n",
      "episode:  85\n",
      "episode:  86\n",
      "episode:  87\n",
      "episode:  88\n",
      "episode:  89\n",
      "episode:  90\n",
      "episode:  91\n",
      "episode:  92\n",
      "episode:  93\n",
      "episode:  94\n",
      "episode:  95\n",
      "episode:  96\n",
      "episode:  97\n",
      "episode:  98\n",
      "episode:  99\n",
      "training completed.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "alpha = 0.1 \n",
    "gamma = 0.99  \n",
    "epsilon = 0.6  \n",
    "num_episodes = 100\n",
    "\n",
    "\n",
    "Q = np.zeros((env.observation_space.n, env.action_space.n))\n",
    "\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    state, _ = env.reset()\n",
    "    done = False\n",
    "    print(\"episode: \", episode)\n",
    "\n",
    "    while not done:\n",
    "\n",
    "        if random.uniform(0, 1) < epsilon:\n",
    "            action = env.action_space.sample()  \n",
    "        else:\n",
    "            action = np.argmax(Q[state])  \n",
    "        next_state, reward, done, truncated, info = env.step(action)\n",
    "        Q[state, action] = Q[state, action] + alpha * (reward + gamma * np.max(Q[next_state]) - Q[state, action])\n",
    "        state = next_state\n",
    "print(\"training completed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
