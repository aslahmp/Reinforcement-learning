{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyIteration:\n",
    "    def __init__(self, states, actions, transition_probabilities,  discount_factor):\n",
    "        self.states = states\n",
    "        self.actions = actions\n",
    "        self.transition_probabilities = transition_probabilities\n",
    "        \n",
    "        self.discount_factor = discount_factor\n",
    "        self.policy = {state: actions[0] for state in states}\n",
    "        self.value_function = {state: 0 for state in states}\n",
    "    def reward(self, state,next_state):\n",
    "        if next_state == 15:\n",
    "            return 0\n",
    "        if state ==next_state:\n",
    "            return -10\n",
    "        return -1\n",
    "    def get_coordinates(self, state):\n",
    "        return state // 4, state % 4\n",
    "    \n",
    "    def isValid(self,s,a):\n",
    "        l=4\n",
    "\n",
    "\n",
    "        return (s+a>=0 and s+a<l)\n",
    "    def tau(self,s,a):\n",
    "\n",
    "        if(a=='up'):#up\n",
    "            if(self.isValid(s[0],-1)):\n",
    "                return (s[0]-1,s[1])\n",
    "        elif(a=='down'):#down\n",
    "            if(self.isValid(s[0],+1)):\n",
    "                return (s[0]+1,s[1])\n",
    "        elif(a=='left'):#left\n",
    "            if(self.isValid(s[1],-1)):\n",
    "                return (s[0],s[1]-1)    \n",
    "        elif(a=='right'):#right\n",
    "            if(self.isValid(s[1],1)):\n",
    "                return (s[0],s[1]+1)    \n",
    "        return(s)\n",
    "    def idq(self,s):\n",
    "\n",
    "\n",
    "        return ((s[0])*4)+s[1]\n",
    "    def nextState(self, state, action):\n",
    "        if state == 15:\n",
    "            return 15\n",
    "        row, col = self.get_coordinates(state)\n",
    "\n",
    "        s= self.tau((row, col), action)\n",
    "        return self.idq(s)\n",
    "\n",
    "    def policy_evaluation(self):\n",
    "            theta = 1e-6\n",
    "            while True:\n",
    "                delta = 0\n",
    "                for state in self.states:\n",
    "                    v = self.value_function[state]\n",
    "                    actions= self.policy[state]\n",
    "                    next_state = self.nextState(state, actions)\n",
    "                    new_value = (self.reward(state,next_state) +self.transition_probabilities[state, next_state] *  self.discount_factor * self.value_function[next_state])\n",
    "                                     \n",
    "                    self.value_function[state] = new_value\n",
    "\n",
    "\n",
    "                    delta = max(delta, abs(v - new_value))\n",
    "\n",
    "                if delta < theta:\n",
    "                    break\n",
    "\n",
    "\n",
    "    def policy_improvement(self):\n",
    "\n",
    "\n",
    "        policy_stable = True\n",
    "        for state in self.states:\n",
    "            old_action = self.policy[state]\n",
    "            action_values = []\n",
    "            for action in self.actions:\n",
    "                next_state = self.nextState(state, action)\n",
    "\n",
    "                action_value = (self.reward(state,next_state) +self.transition_probabilities[state, next_state] *  self.discount_factor * self.value_function[next_state])\n",
    "                                   \n",
    "                action_values.append(action_value)\n",
    "\n",
    "            best_action = self.actions[np.argmax(action_values)]\n",
    "\n",
    "            self.policy[state] = best_action\n",
    "            if old_action != best_action:\n",
    "                policy_stable = False\n",
    "        return policy_stable\n",
    "\n",
    "    def show(self):\n",
    "        for i in range(4):\n",
    "            print('\\n')\n",
    "            for j in range(4):\n",
    "                id=self.idq((i,j))\n",
    "                print(self.policy[id],end=\"\\t\")\n",
    "    def iterate_policy(self):\n",
    "\n",
    "        is_policy_stable = False\n",
    "        while not is_policy_stable:\n",
    "            self.policy_evaluation()\n",
    "            self.show()\n",
    "            print('\\n----')\n",
    "            is_policy_stable = self.policy_improvement()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_probabilities=np.array([[0,0.8,0,0,0.2,0,0,0,0,0,0,0,0,0,0,0],\n",
    "            [0.1,0,0.8,0,0,0.1,0,0,0,0,0,0,0,0,0,0],\n",
    "            [0,0.1,0,0.8,0,0,0.1,0,0,0,0,0,0,0,0,0],\n",
    "            [0,0,0.2,0,0,0,0,0.8,0,0,0,0,0,0,0,0],\n",
    "             [0.1,0,0,0,0,0.8,0,0,0.1,0,0,0,0,0,0,0],\n",
    "              [0,0.1,0,0,0,0,0.8,0,0,0.1,0,0,0,0,0,0],\n",
    "               [0,0,0.1,0,0,0,0,0.8,0,0,0.1,0,0,0,0,0],\n",
    "            [0,0,0,0.1,0,0,0.1,0,0,0,0,0.8,0,0,0,0],\n",
    "             [0,0,0,0,0.1,0,0,0,0,0.8,0,0,0.1,0,0,0],\n",
    "            [0,0,0,0,0,0.1,0,0,0,0,0.8,0,0,0.1,0,0],\n",
    "            [0,0,0,0,0,0,0.1,0,0,0,0,0.8,0,0,0.1,0],\n",
    "            [0,0,0,0,0,0,0,0.1,0,0,0.1,0,0,0,0,0.8],\n",
    "            [0,0,0,0,0,0,0,0,0.2,0,0,0,0,0.8,0,0],\n",
    "            [0,0,0,0,0,0,0,0,0,0.1,0,0,0.1,0,0.8,0],\n",
    "            [0,0,0,0,0,0,0,0,0,0,0.1,0,0,0.1,0,0.8],\n",
    "            [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "up\tup\tup\tup\t\n",
      "\n",
      "up\tup\tup\tup\t\n",
      "\n",
      "up\tup\tup\tup\t\n",
      "\n",
      "up\tup\tup\tup\t\n",
      "----\n",
      "\n",
      "\n",
      "down\tdown\tdown\tdown\t\n",
      "\n",
      "down\tleft\tleft\tleft\t\n",
      "\n",
      "down\tleft\tleft\tdown\t\n",
      "\n",
      "up\tup\tright\tup\t\n",
      "----\n",
      "\n",
      "\n",
      "down\tdown\tdown\tleft\t\n",
      "\n",
      "down\tleft\tleft\tdown\t\n",
      "\n",
      "up\tleft\tdown\tdown\t\n",
      "\n",
      "up\tright\tright\tup\t\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "actions = ['up', 'down', 'left', 'right']\n",
    "states = list(range(16))\n",
    "\n",
    "\n",
    "discount_factor = 0.9\n",
    "policy_iteration = PolicyIteration(states, actions, transition_probabilities,  discount_factor)\n",
    "policy_iteration.iterate_policy()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "down\tdown\tdown\tleft\t\n",
      "\n",
      "down\tleft\tleft\tdown\t\n",
      "\n",
      "up\tleft\tdown\tdown\t\n",
      "\n",
      "up\tright\tright\tup\t"
     ]
    }
   ],
   "source": [
    "policy_iteration.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
